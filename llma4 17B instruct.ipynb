{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12508883,"sourceType":"datasetVersion","datasetId":7895256}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install groq langchain-community pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T13:59:18.346489Z","iopub.execute_input":"2025-07-18T13:59:18.347029Z","iopub.status.idle":"2025-07-18T13:59:21.583861Z","shell.execute_reply.started":"2025-07-18T13:59:18.346971Z","shell.execute_reply":"2025-07-18T13:59:21.583105Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.30.0)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\nRequirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.7)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.66)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250506)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (44.0.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import json\nfrom groq import Groq\nfrom langchain_community.document_loaders import PDFPlumberLoader\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T13:59:21.585282Z","iopub.execute_input":"2025-07-18T13:59:21.585471Z","iopub.status.idle":"2025-07-18T13:59:23.086529Z","shell.execute_reply.started":"2025-07-18T13:59:21.585450Z","shell.execute_reply":"2025-07-18T13:59:23.085814Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GROQ_API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T13:59:28.459659Z","iopub.execute_input":"2025-07-18T13:59:28.460065Z","iopub.status.idle":"2025-07-18T13:59:28.625532Z","shell.execute_reply.started":"2025-07-18T13:59:28.460042Z","shell.execute_reply":"2025-07-18T13:59:28.625002Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"system_prompt = \"\"\"You are an AI assistant designed to extract structured resume data.\n                   Always respond with a strictly valid JSON object. Use `null` for missing values,\n                   ensuring compliance with JSON standards. Do not include explanations,\n                   comments, or any additional text outside the JSON structure.\n                \"\"\"\n\n\n\nhuman_prompt = \"\"\"\n             **Task:** Extract key information from the following resume text.\n\n            **Resume Text:**\n            {context}\n\n            **Instructions:**\n            Please extract the following information and format it in a clear structure:\n\n            1. **Contact Information:**\n            - Name:\n            - Email:\n            - Phone Number:\n            - Website/Portfolio/LinkedIn:\n            - Github Profile:\n\n            2. **Education:**\n            - Institution Name:\n            - Degree:\n            - Graduation Date:\n\n            3. **Experience:**\n            - Job Title:\n            - Company Name:\n            - Location:\n            - Dates of Employment:\n            - Description:\n\n            5. **Skills:**\n            - Skills:\n\n            **Question:**\n            Extract this information as a structured and valid JSON object. Use `null` for missing or unavailable valuesDo not include explanations,\n                   comments, or any additional text outside the JSON structure.\n        \"\"\"\n\n\n\n# Initialize Groq client once\nclient = Groq(api_key=secret_value_0) \n\n# Your system and human prompts (define these before the loop)\nsystem_prompt = system_prompt\nhuman_prompt = human_prompt\n\ndef clean_resume_data(json_data):\n    \"\"\"Clean and standardize the resume JSON data\"\"\"\n    # 1. Remove duplicate skills (case insensitive)\n    if 'skills' in json_data and isinstance(json_data['skills'], list):\n        seen_skills = set()\n        unique_skills = []\n        for skill in json_data['skills']:\n            lower_skill = skill.strip().lower()\n            if lower_skill not in seen_skills:\n                seen_skills.add(lower_skill)\n                unique_skills.append(skill.strip())\n        json_data['skills'] = unique_skills\n    \n    # 2. Standardize website/portfolio fields\n    website_aliases = [\n        'website', 'portfolio', 'linkedin', \n        'Website', 'Portfolio', 'LinkedIn',\n        'personal_website', 'webpage'\n    ]\n    \n    # Find the first existing website-related field\n    website_field = None\n    website_value = None\n    for field in website_aliases:\n        if field in json_data:\n            website_field = field\n            website_value = json_data[field]\n            break\n    \n    # Standardize to 'website' if we found a value\n    if website_field and website_value:\n        # Remove all website-related fields\n        for field in website_aliases:\n            if field in json_data:\n                del json_data[field]\n        # Add the standardized field\n        json_data['website'] = website_value.strip()\n    \n    return json_data\n\ndef extract_text_pdf(pdf_path):\n    loader = PDFPlumberLoader(pdf_path)\n    docs = loader.load()\n    text = ''\n    for doc in docs:\n        text += doc.page_content\n    return text\n\ndef process_resume(pdf_path, index):\n    # Extract text from PDF\n    context = extract_text_pdf(pdf_path)\n    \n    # Call LLM API\n    completion = client.chat.completions.create(\n        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": human_prompt.format(context=context)\n            }\n        ],\n        temperature=1,\n        max_completion_tokens=1024,\n        top_p=1,\n        stream=True,\n        stop=None,\n    )\n    \n    # Process the streamed output\n    output = \"\"\n    for chunk in completion:\n        content = chunk.choices[0].delta.content or \"\"\n        print(content, end=\"\")\n        output += content\n    \n    # Extract JSON content\n    json_start = output.find('{')\n    json_end = output.rfind('}') + 1\n    json_content = output[json_start:json_end]\n    \n    # Save JSON to file\n    try:\n        json_data = json.loads(json_content)\n        \n        # Clean and standardize the data\n        cleaned_data = clean_resume_data(json_data)\n        \n        output_filename = f\"Resume_data_pdf_{index}.json\"\n        with open(output_filename, 'w') as f:\n            json.dump(cleaned_data, f, indent=2)\n        print(f\"\\nJSON saved successfully to {output_filename}\")\n        return True\n    except json.JSONDecodeError as e:\n        print(f\"Error parsing JSON for {pdf_path}: {e}\")\n        # Save raw output for debugging\n        with open(f\"Raw_output_pdf_{index}.json\", 'w') as f:\n            f.write(output)\n        return False\n\n\n\n# # # Correct paths (/) # working\n# pdf_path1 = \"/kaggle/input/resume-17b/BHARATH_RESUME-complete.pdf\"\n# pdf_path2 = \"/kaggle/input/resume-17b/Bharathkumar-Parunandula-Resume.pdf\"   \n# pdf_path3 = \"/kaggle/input/retsdts/BHARATH_RESUME-DS-FINAL.pdf\"   \n# # pdf_path4 = \"PARSER-APP INPUT/50328713.rank4.pdf\"\n# # pdf_path5 = \"PARSER-APP INPUT/17823436.rank5.pdf\"\n\n\n# import os\n\npdf_paths = []\nfor dirname, _, filenames in os.walk('/kaggle/input/testlres'):\n    for filename in filenames:\n        if filename.lower().endswith('.pdf'):\n            pdf_paths.append(os.path.join(dirname, filename))\n\nprint(\"Found PDF files:\")\nfor path in pdf_paths:\n    print(path)\n\n# Process each PDF separately\n# pdf_paths = [pdf_path1,pdf_path2,pdf_path3]\nfor i, pdf_path in enumerate(pdf_paths, start=1):\n    print(f\"\\nProcessing resume {i}: {pdf_path}\")\n    process_resume(pdf_path, i)\n    print(f\"Completed processing {pdf_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T14:13:12.867040Z","iopub.execute_input":"2025-07-18T14:13:12.867591Z","iopub.status.idle":"2025-07-18T14:13:37.627806Z","shell.execute_reply.started":"2025-07-18T14:13:12.867571Z","shell.execute_reply":"2025-07-18T14:13:37.626965Z"}},"outputs":[{"name":"stdout","text":"Found PDF files:\n/kaggle/input/testlres/cover letter.pdf\n/kaggle/input/testlres/BHARATH_RESUME-DS_final.pdf\n/kaggle/input/testlres/BHARATH-RESUME V3.pdf\n/kaggle/input/testlres/BHARATH_RESUME-DS-FINAL.pdf\n/kaggle/input/testlres/Bharathkumar-Parunandula-Resume.pdf\n/kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250704.pdf\n/kaggle/input/testlres/BHARATH_RESUME-DS-3.pdf\n/kaggle/input/testlres/Bharathkumar-Parunandula-resume-final.pdf\n/kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250619.pdf\n/kaggle/input/testlres/BHARATH-RESUME-DS.pdf\n/kaggle/input/testlres/BHARATH_RESUME-DS2.pdf\n/kaggle/input/testlres/BHARATH_RESUME-complete.pdf\n/kaggle/input/testlres/BHARATH-RESUME V2.pdf\n/kaggle/input/testlres/cover1.pdf\n/kaggle/input/testlres/Bharathkumar Original Resume 2.pdf\n/kaggle/input/testlres/BHARATH-RESUME.pdf\n/kaggle/input/testlres/BHARATH_RESUMEDSv4.pdf\n/kaggle/input/testlres/BHARATH_RESUMEDS.pdf\n\nProcessing resume 1: /kaggle/input/testlres/cover letter.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": null,\n    \"Phone Number\": null,\n    \"Website/Portfolio/LinkedIn\": null,\n    \"Github Profile\": null\n  },\n  \"Education\": {\n    \"Institution Name\": null,\n    \"Degree\": null,\n    \"Graduation Date\": null\n  },\n  \"Experience\": [\n    {\n      \"Job Title\": null,\n      \"Company Name\": null,\n      \"Location\": null,\n      \"Dates of Employment\": null,\n      \"Description\": \"Developed a RAG-Powered Candidate Retrieval System using FAISS and embeddings, increasing precision by ~40% through gte-small contextual re-ranking with Flashrank. Built an AI Resume Parser & Structured Extractor, leveraging Groq's LLaMA3-70B and LangChain to convert resumes into clean, ATS-friendly JSON. Created a Resume Scoring Engine that ranks resumes against job descriptions using MiniLM embeddings and a configurable scoring algorithm. Launched an AI-Powered Feedback & Skill Gap Analyzer that assesses alignment between resumes and JDs, identifies missing skills, and provides actionable suggestions.\"\n    }\n  ],\n  \"Skills\": {\n    \"Skills\": [\n      \"AI\",\n      \"NLP\",\n      \"Data Science\",\n      \"Semantic Retrieval\",\n      \"Information Extraction\",\n      \"Scoring Engines\",\n      \"Automated Feedback Systems\",\n      \"FAISS\",\n      \"Embeddings\",\n      \"LLaMA3-70B\",\n      \"LangChain\",\n      \"MiniLM\",\n      \"Groq\"\n    ]\n  }\n}\n```\nJSON saved successfully to Resume_data_pdf_1.json\nCompleted processing /kaggle/input/testlres/cover letter.pdf\n\nProcessing resume 2: /kaggle/input/testlres/BHARATH_RESUME-DS_final.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Project Name\": \"RAG-POWERED CANDIDATE RETRIEVAL SYSTEM WITH CONTEXTUAL RERANKING\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements.\"\n    },\n    {\n      \"Project Name\": \"AI RESUME PARSER & STRUCTURED DATA EXTRACTION TOOL\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq’s LLaMA3-70B and LangChain.\"\n    },\n    {\n      \"Project Name\": \"RESUMESCORINGENGINE:MATCHCANDIDATESWITHJOBDESCRIPTIONS\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring.\"\n    },\n    {\n      \"Project Name\": \"AI-POWERED RESUME FEEDBACK & SKILL GAP ANALYSIS SYSTEM\",\n      \"Description\": \"AI tool using Groq’s Llama3-70B to analyze resume-JD alignment with detailed feedback.\"\n    }\n  ],\n  \"Certifications\": [\n    \"Python for Everybody - Coursera\",\n    \"Python Data Structures\",\n    \"Using Python to Access Web Data\",\n    \"Using Databases with Python\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_2.json\nCompleted processing /kaggle/input/testlres/BHARATH_RESUME-DS_final.pdf\n\nProcessing resume 3: /kaggle/input/testlres/BHARATH-RESUME V3.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"https://linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"https://github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": {\n    \"Job Title\": null,\n    \"Company Name\": null,\n    \"Location\": null,\n    \"Dates of Employment\": null,\n    \"Description\": null\n  },\n  \"Skills\": {\n    \"Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Hugging Face\",\n      \"LangChain\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"CSV\",\n      \"JSON\",\n      \"API\",\n      \"Jupyter\",\n      \"Colab\",\n      \"Kaggle\",\n      \"VS Code\",\n      \"Feature Engineering\",\n      \"Prompt Engineering\",\n      \"Visualization\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Name\": \"RAG-Powered Candidate Retrieval System with Contextual Reranking\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements.\"\n    },\n    {\n      \"Name\": \"AI Resume Parser & Structured Data Extraction Tool\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq’s LLaMA3-70B and LangChain.\"\n    },\n    {\n      \"Name\": \"Resume Scoring Engine: Match Candidates with Job Descriptions\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & case-insensitive normalization.\"\n    },\n    {\n      \"Name\": \"AI-Powered Resume Feedback & Skill Gap Analysis System\",\n      \"Description\": \"Developed an AI-driven tool using Groq’s Llama3-70B model to analyze resume-JD alignment, generating structured feedback on key strengths, missing skills, and improvement areas.\"\n    }\n  ],\n  \"Certifications\": [\n    {\n      \"Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera\",\n      \"Credential\": \"https://www.coursera.org/account/accomplishments/specialization/LMST7ZT2F8LD\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_3.json\nCompleted processing /kaggle/input/testlres/BHARATH-RESUME V3.pdf\n\nProcessing resume 4: /kaggle/input/testlres/BHARATH_RESUME-DS-FINAL.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Technical Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\",\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\",\n      \"CSV\",\n      \"JSON\",\n      \"API integration\",\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\",\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"NLP\",\n      \"Machine Learning\",\n      \"Large Language Models (LLMs)\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Project Name\": \"RAG-POWERED CANDIDATE RETRIEVAL SYSTEM WITH CONTEXTUAL RERANKING\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements.\"\n    },\n    {\n      \"Project Name\": \"AI RESUME PARSER & STRUCTURED DATA EXTRACTION TOOL\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq’s LLaMA3-70B and LangChain.\"\n    },\n    {\n      \"Project Name\": \"RESUMESCORINGENGINE:MATCHCANDIDATESWITHJOBDESCRIPTIONS\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring.\"\n    },\n    {\n      \"Project Name\": \"AI-POWERED RESUME FEEDBACK & SKILL GAP ANALYSIS SYSTEM\",\n      \"Description\": \"AI tool using Groq’s Llama3-70B to analyze resume-JD alignment with detailed feedback.\"\n    }\n  ],\n  \"Certifications\": [\n    \"Python for Everybody - Coursera\",\n    \"Python Data Structures\",\n    \"Using Python to Access Web Data\",\n    \"Using Databases with Python\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_4.json\nCompleted processing /kaggle/input/testlres/BHARATH_RESUME-DS-FINAL.pdf\n\nProcessing resume 5: /kaggle/input/testlres/Bharathkumar-Parunandula-Resume.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+918639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"https://www.kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null,\n    \"Location\": \"Hyderabad, India\"\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"Visual Studio Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    {\n      \"Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera Specialization\",\n      \"Certificate URL\": \"https://www.coursera.org/account/accomplishments/specialization/LMST7ZT2F8LD\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_5.json\nCompleted processing /kaggle/input/testlres/Bharathkumar-Parunandula-Resume.pdf\n\nProcessing resume 6: /kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250704.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+918639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"https://www.kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"Visual Studio Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    {\n      \"Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera Specialization\",\n      \"Certificate URL\": \"https://www.coursera.org/account/accomplishments/specialization/LMST7ZT2F8LD\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_6.json\nCompleted processing /kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250704.pdf\n\nProcessing resume 7: /kaggle/input/testlres/BHARATH_RESUME-DS-3.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Technical Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\",\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\",\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\",\n      \"CSV\",\n      \"JSON\",\n      \"API integration\",\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"NLP\",\n      \"Machine Learning\",\n      \"Large Language Models (LLMs)\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Project Name\": \"RAG-POWERED CANDIDATE RETRIEVAL SYSTEM WITH CONTEXTUAL RERANKING\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements. Implemented FAISS vector storage with 'gte-small' embeddings for efficient cosine similarity search. Boosted precision by 40% using Flashrank reranking, surfacing optimal candidates through contextual reordering.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Hugging Face Transformers\",\n        \"LangChain\",\n        \"FAISS\",\n        \"Flashrank\"\n      ]\n    },\n    {\n      \"Project Name\": \"AI RESUME PARSER & STRUCTURED DATA EXTRACTION TOOL\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq's LLaMA3-70B and LangChain.\",\n      \"Key Features\": [\n        \"PDF Text Extraction: Accurate data capture via PDFPlumber.\",\n        \"LLM-Powered Parsing: Normalized contact info, skills, and work history.\",\n        \"ATS-Optimized Output: JSON with standardized fields (e.g., skills: [\\\"Python\\\", \\\"SQL\\\"]).\",\n        \"Dynamic UI: Upload resumes, preview data, and download JSON.\"\n      ],\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Groq API\",\n        \"LangChain\",\n        \"PDFPlumber\"\n      ]\n    },\n    {\n      \"Project Name\": \"RESUMESCORINGENGINE:MATCHCANDIDATESWITHJOBDESCRIPTIONS\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring. Weighted scoring: Skills(40%), Experience(40%), Education(10%), Keywords(10%). Built Streamlit dashboard with model selection, batch processing, and visualizations.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Sentence-Transformers\",\n        \"Matplotlib\"\n      ]\n    },\n    {\n      \"Project Name\": \"AI-POWERED RESUME FEEDBACK & SKILL GAP ANALYSIS SYSTEM\",\n      \"Description\": \"AI tool using Groq's Llama3-70B to analyze resume-JD alignment with detailed feedback. Implemented synonym matching, skill gap detection, and penalty scoring for core competencies. Outputs structured insights highlighting strengths and areas for growth.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Groq API\",\n        \"Llama3-70B\"\n      ]\n    }\n  ],\n  \"Certifications\": [\n    {\n      \"Certification Name\": \"Python for Everybody\",\n      \"Issuer\": \"Coursera\"\n    },\n    {\n      \"CertificationError parsing JSON for /kaggle/input/testlres/BHARATH_RESUME-DS-3.pdf: Expecting ',' delimiter: line 127 column 6 (char 4109)\nCompleted processing /kaggle/input/testlres/BHARATH_RESUME-DS-3.pdf\n\nProcessing resume 8: /kaggle/input/testlres/Bharathkumar-Parunandula-resume-final.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+918639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"https://www.kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"Institute of Aeronautical Engineering\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null,\n    \"Location\": \"Hyderabad, India\"\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"Visual Studio Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    {\n      \"Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera\",\n      \"Certificate URL\": \"https://www.coursera.org/account/accomplishments/specialization/LMST7ZT2F8LD\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_8.json\nCompleted processing /kaggle/input/testlres/Bharathkumar-Parunandula-resume-final.pdf\n\nProcessing resume 9: /kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250619.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+918639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"https://www.kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Technical Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\",\n      \"Llama3\",\n      \"Hugging Face Transformers\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\",\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\"\n    ],\n    \"Soft Skills\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    {\n      \"Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera\",\n      \"Certificate URL\": \"coursera.org/account/accomplishments/specialization/LMST7ZT2F8LD\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_9.json\nCompleted processing /kaggle/input/testlres/Bharathkumar-Parunandula-FlowCV-Resume-20250619.pdf\n\nProcessing resume 10: /kaggle/input/testlres/BHARATH-RESUME-DS.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Technical Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\",\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\",\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle\",\n      \"Notebooks\",\n      \"VS Code\"\n    ],\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle\",\n      \"Notebooks\",\n      \"VS Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Project Name\": \"RAG-Powered Candidate Retrieval System with Contextual Reranking\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements.\"\n    },\n    {\n      \"Project Name\": \"AI Resume Parser & Structured Data Extraction Tool\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq’s LLaMA3-70B and LangChain.\"\n    },\n    {\n      \"Project Name\": \"Resume Scoring Engine: Match Candidates with Job Descriptions\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring.\"\n    },\n    {\n      \"Project Name\": \"AI-Powered Resume Feedback & Skill Gap Analysis System\",\n      \"Description\": \"AI tool using Groq’s Llama3-70B to analyze resume-JD alignment with detailed feedback.\"\n    }\n  ],\n  \"Certifications\": [\n    \"Python for Everybody - Coursera\",\n    \"Python Data Structures\",\n    \"Using Python to Access Web Data\",\n    \"Using Databases with Python\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_10.json\nCompleted processing /kaggle/input/testlres/BHARATH-RESUME-DS.pdf\n\nProcessing resume 11: /kaggle/input/testlres/BHARATH_RESUME-DS2.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle\",\n      \"Notebooks\",\n      \"VS Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Projects\": [\n    {\n      \"Project Name\": \"RAG-Powered Candidate Retrieval System with Contextual Reranking\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements. Implemented FAISS vector storage with 'gte-small' embeddings for efficient cosine similarity search. Boosted precision by 40% using Flashrank reranking, surfacing optimal candidates through contextual reordering.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Hugging Face Transformers\",\n        \"LangChain\",\n        \"FAISS\",\n        \"Flashrank\"\n      ]\n    },\n    {\n      \"Project Name\": \"AI Resume Parser & Structured Data Extraction Tool\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq's LLaMA3-70B and LangChain.\",\n      \"Key Features\": [\n        \"PDF Text Extraction: Accurate data capture via PDFPlumber.\",\n        \"LLM-Powered Parsing: Normalized contact info, skills, and work history.\",\n        \"ATS-Optimized Output: JSON with standardized fields (e.g., skills: [\\\"Python\\\", \\\"SQL\\\"]).\",\n        \"Dynamic UI: Upload resumes, preview data, and download JSON.\"\n      ],\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Groq API\",\n        \"LangChain\",\n        \"PDFPlumber\"\n      ]\n    },\n    {\n      \"Project Name\": \"Resume Scoring Engine: Match Candidates with Job Descriptions\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring. Weighted scoring: Skills(40%), Experience(40%), Education(10%), Keywords(10%). Built Streamlit dashboard with model selection, batch processing, and visualizations.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Sentence-Transformers\",\n        \"Matplotlib\"\n      ]\n    },\n    {\n      \"Project Name\": \"AI-Powered Resume Feedback & Skill Gap Analysis System\",\n      \"Description\": \"AI tool using Groq's Llama3-70B to analyze resume-JD alignment with detailed feedback. Implemented synonym matching, skill gap detection, and penalty scoring for core competencies. Outputs structured insights highlighting strengths and areas for growth.\",\n      \"Tech Stack\": [\n        \"Python\",\n        \"Streamlit\",\n        \"Groq API\",\n        \"Llama3-70B\"\n      ]\n    }\n  ],\n  \"Certifications\": [\n    {\n      \"Certification Name\": \"Python for Everybody\",\n      \"Issuing Organization\": \"Coursera\"\n    },\n    {\n      \"Certification Name\": \"Python Data Structures\",\n      \"Issuing Organization\": \"Coursera\"\n    },\n    {\n      \"Certification Name\": \"Using Python to Access Web Data\",\n      \"Issuing Organization\": \"Coursera\"\n    },\n    {\n      \"Certification Name\": \"Using Databases with Python\",\n      \"Issuing Organization\": \"Coursera\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_11.json\nCompleted processing /kaggle/input/testlres/BHARATH_RESUME-DS2.pdf\n\nProcessing resume 12: /kaggle/input/testlres/BHARATH_RESUME-complete.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathkumar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": [\n      \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n      \"github.com/Bharathkumar1011\",\n      \"kaggle.com/work/collections\"\n    ],\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"GitHub\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"VS Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    \"Python for Everybody - Coursera\",\n    \"Python Data Structures\",\n    \"Using Python to Access Web Data\",\n    \"Using Databases with Python\"\n  ],\n  \"Projects\": [\n    {\n      \"Name\": \"RAG-POWERED CANDIDATE RETRIEVAL SYSTEM WITH CONTEXTUAL RERANKING\",\n      \"Description\": \"Developed AI-powered resume search system using NLP and vector databases to match 1,000+ resumes with complex job requirements.\"\n    },\n    {\n      \"Name\": \"AI RESUME PARSER & STRUCTURED DATA EXTRACTION TOOL\",\n      \"Description\": \"Developed a Streamlit web app that parses resumes (PDFs) into structured JSON data using Groq’s LLaMA3-70B and LangChain.\"\n    },\n    {\n      \"Name\": \"RESUMESCORINGENGINE:MATCHCANDIDATESWITHJOBDESCRIPTIONS\",\n      \"Description\": \"Parsed nested JSON resumes with prioritized key extraction & normalization. Matched job descriptions using MiniLM-based embeddings for skill/edu/exp scoring.\"\n    },\n    {\n      \"Name\": \"AI-POWERED RESUME FEEDBACK & SKILL GAP ANALYSIS SYSTEM\",\n      \"Description\": \"AI tool using Groq’s Llama3-70B to analyze resume-JD alignment with detailed feedback. Implemented synonym matching, skill gap detection, and penalty scoring for core competencies.\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_12.json\nCompleted processing /kaggle/input/testlres/BHARATH_RESUME-complete.pdf\n\nProcessing resume 13: /kaggle/input/testlres/BHARATH-RESUME V2.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Bharathkumar Parunandula\",\n    \"Email\": \"bharathku-mar1011@gmail.com\",\n    \"Phone Number\": \"+91 8639078566\",\n    \"Website/Portfolio/LinkedIn\": \"linkedin.com/in/bharathkumar-parunandula-23021bb1\",\n    \"Github Profile\": \"github.com/Bharathkumar1011\"\n  },\n  \"Education\": {\n    \"Institution Name\": \"INSTITUTE OF AERONAUTICAL ENGINEERING\",\n    \"Degree\": \"Bachelor of Engineering - Aeronautical Engineering\",\n    \"Graduation Date\": null\n  },\n  \"Experience\": null,\n  \"Skills\": {\n    \"Technical Skills\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\",\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama 3\",\n      \"SpaCy\",\n      \"Regex\",\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\",\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"Visual Studio Code\"\n    ],\n    \"Languages & Libraries\": [\n      \"Python\",\n      \"NumPy\",\n      \"Pandas\",\n      \"Scikit-learn\",\n      \"Matplotlib\",\n      \"Seaborn\"\n    ],\n    \"Machine Learning & NLP\": [\n      \"Hugging Face Transformers\",\n      \"LangChain\",\n      \"Llama 3\",\n      \"SpaCy\",\n      \"Regex\"\n    ],\n    \"Web & Deployment\": [\n      \"Streamlit\",\n      \"Flask\",\n      \"Git\"\n    ],\n    \"Data Handling\": [\n      \"CSV\",\n      \"JSON\",\n      \"API integration\"\n    ],\n    \"Tools & Platforms\": [\n      \"Jupyter\",\n      \"Google Colab\",\n      \"Kaggle Notebooks\",\n      \"Visual Studio Code\"\n    ],\n    \"Other\": [\n      \"Data Wrangling\",\n      \"Feature Engineering\",\n      \"Data Visualization\",\n      \"Prompt Engineering\"\n    ]\n  },\n  \"Certifications\": [\n    \"Python for Everybody - Coursera Specialization\",\n    \"Python Data Structures\",\n    \"Using Python to Access Web Data\",\n    \"Using Databases with Python\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_13.json\nCompleted processing /kaggle/input/testlres/BHARATH-RESUME V2.pdf\n\nProcessing resume 14: /kaggle/input/testlres/cover1.pdf\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPDFSyntaxError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, stream_is_external, path, pages, laparams, password, strict_metadata, unicode_norm, raise_unicode_errors)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pdfminer/pdfdocument.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, password, caching, fallback)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPDFSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No /Root object! - Is this really a PDF?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mLITERAL_CATALOG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPDFSyntaxError\u001b[0m: No /Root object! - Is this really a PDF?","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPdfminerException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2434462952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nProcessing resume {i}: {pdf_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mprocess_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Completed processing {pdf_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2434462952.py\u001b[0m in \u001b[0;36mprocess_resume\u001b[0;34m(pdf_path, index)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Extract text from PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# Call LLM API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2434462952.py\u001b[0m in \u001b[0;36mextract_text_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFPlumberLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/document_loaders/base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/parsers/pdf.py\u001b[0m in \u001b[0;36mlazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# open document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             yield from [\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             return cls(\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, stream_is_external, path, pages, laparams, password, strict_metadata, unicode_norm, raise_unicode_errors)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPdfminerException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsrcmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFResourceManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPdfminerException\u001b[0m: No /Root object! - Is this really a PDF?"],"ename":"PdfminerException","evalue":"No /Root object! - Is this really a PDF?","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"# isuue 1 - can't parse resume that stetches into two pages properly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T14:09:52.798501Z","iopub.execute_input":"2025-07-18T14:09:52.798761Z","iopub.status.idle":"2025-07-18T14:09:52.802858Z","shell.execute_reply.started":"2025-07-18T14:09:52.798741Z","shell.execute_reply":"2025-07-18T14:09:52.802174Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}